{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as plb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Conv2D, Lambda, MaxPooling2D, Dropout\n",
    "from keras.utils import print_summary\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG16\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from scipy import pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27342 validated image filenames.\n",
      "Found 9113 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "trainDF = pd.read_csv('/home/jupyter/Project/train.txt', sep=\" \", header=None)\n",
    "trainDF.columns = ['Images', 'SteeringAngle'] \n",
    "trainDF['SteeringAngle'] = trainDF['SteeringAngle'] * (pi / 180)\n",
    "\n",
    "testDF = pd.read_csv('/home/jupyter/Project/test.txt', sep=\" \", header=None)\n",
    "testDF.columns = ['Images', 'SteeringAngle'] \n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            validation_split=0.25)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=trainDF,\n",
    "directory=\"/home/jupyter/Project/train/\",\n",
    "x_col=\"Images\",\n",
    "y_col=\"SteeringAngle\",\n",
    "subset=\"training\",\n",
    "batch_size=100,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=\"raw\",\n",
    "target_size=(200,66))\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "dataframe=trainDF,\n",
    "directory=\"/home/jupyter/Project/train/\",\n",
    "x_col=\"Images\",\n",
    "y_col=\"SteeringAngle\",\n",
    "subset=\"validation\",\n",
    "batch_size=100,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=\"raw\",\n",
    "target_size=(200,66))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def VGG_DataAug(width, height, depth):\n",
    "\n",
    "    conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(height, width, depth))\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(conv_base)\n",
    "    conv_base.trainable = False\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(Dense(1164, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='relu'))    \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 6, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1164)              7152780   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1164)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 21,989,539\n",
      "Trainable params: 7,274,851\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "329/329 [==============================] - 247s 751ms/step - loss: 0.2350 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00361, saving model to /home/jupyter/Project/VGG/VGG_DA_Chekpoints/VGG_DA_weights.01-0.00.h5\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.5/site-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 240s 731ms/step - loss: 0.1750 - val_loss: 0.0030\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00361 to 0.00304, saving model to /home/jupyter/Project/VGG/VGG_DA_Chekpoints/VGG_DA_weights.02-0.00.h5\n",
      "Epoch 3/30\n",
      "329/329 [==============================] - 237s 721ms/step - loss: 0.2023 - val_loss: 1.7051e-05\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00304 to 0.00002, saving model to /home/jupyter/Project/VGG/VGG_DA_Chekpoints/VGG_DA_weights.03-0.00.h5\n",
      "Epoch 4/30\n",
      "329/329 [==============================] - 237s 721ms/step - loss: 0.2265 - val_loss: 0.0017\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00002\n",
      "Epoch 5/30\n",
      "329/329 [==============================] - 236s 719ms/step - loss: 0.2080 - val_loss: 0.0022\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00002\n",
      "Epoch 6/30\n",
      "329/329 [==============================] - 237s 721ms/step - loss: 0.1944 - val_loss: 0.0018\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00002\n",
      "Epoch 7/30\n",
      "329/329 [==============================] - 238s 725ms/step - loss: 0.2074 - val_loss: 0.0021\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00002\n",
      "Epoch 8/30\n",
      "329/329 [==============================] - 239s 727ms/step - loss: 0.2053 - val_loss: 1.8209e-04\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00002\n",
      "Epoch 9/30\n",
      "329/329 [==============================] - 236s 718ms/step - loss: 0.2182 - val_loss: 0.0492\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00002\n",
      "Epoch 10/30\n",
      "329/329 [==============================] - 236s 718ms/step - loss: 0.1995 - val_loss: 0.0234\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00002\n",
      "Epoch 11/30\n",
      "329/329 [==============================] - 237s 720ms/step - loss: 0.2023 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00002\n",
      "Epoch 12/30\n",
      "329/329 [==============================] - 237s 719ms/step - loss: 0.2124 - val_loss: 0.0018\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00002\n",
      "Epoch 13/30\n",
      "329/329 [==============================] - 236s 716ms/step - loss: 0.1990 - val_loss: 1.5708e-05\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00002 to 0.00002, saving model to /home/jupyter/Project/VGG/VGG_DA_Chekpoints/VGG_DA_weights.13-0.00.h5\n",
      "Epoch 14/30\n",
      "329/329 [==============================] - 236s 719ms/step - loss: 0.1968 - val_loss: 0.0530\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00002\n",
      "Epoch 15/30\n",
      "329/329 [==============================] - 236s 717ms/step - loss: 0.1978 - val_loss: 15.8482\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00002\n",
      "Epoch 16/30\n",
      "329/329 [==============================] - 236s 716ms/step - loss: 0.1988 - val_loss: 0.0174\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00002\n",
      "Epoch 17/30\n",
      "329/329 [==============================] - 235s 716ms/step - loss: 0.1851 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00002\n",
      "Epoch 18/30\n",
      "329/329 [==============================] - 236s 716ms/step - loss: 0.1941 - val_loss: 0.0019\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00002\n",
      "Epoch 19/30\n",
      "329/329 [==============================] - 236s 716ms/step - loss: 0.1931 - val_loss: 0.0629\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00002\n",
      "Epoch 20/30\n",
      "329/329 [==============================] - 235s 715ms/step - loss: 0.1991 - val_loss: 2.0851\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00002\n",
      "Epoch 21/30\n",
      "329/329 [==============================] - 237s 720ms/step - loss: 0.1695 - val_loss: 0.0351\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00002\n",
      "Epoch 22/30\n",
      "329/329 [==============================] - 236s 719ms/step - loss: 0.1911 - val_loss: 0.0793\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00002\n",
      "Epoch 23/30\n",
      "329/329 [==============================] - 237s 721ms/step - loss: 0.1877 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00002\n",
      "Epoch 24/30\n",
      "329/329 [==============================] - 235s 714ms/step - loss: 0.1800 - val_loss: 0.1097\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00002\n",
      "Epoch 25/30\n",
      "329/329 [==============================] - 236s 716ms/step - loss: 0.1767 - val_loss: 1.0256\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00002\n",
      "Epoch 26/30\n",
      "329/329 [==============================] - 237s 719ms/step - loss: 0.1819 - val_loss: 0.0309\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00002\n",
      "Epoch 27/30\n",
      "329/329 [==============================] - 237s 720ms/step - loss: 0.1491 - val_loss: 0.0430\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00002\n",
      "Epoch 28/30\n",
      "329/329 [==============================] - 237s 719ms/step - loss: 0.1785 - val_loss: 0.0509\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00002\n",
      "Epoch 29/30\n",
      "329/329 [==============================] - 236s 719ms/step - loss: 0.1615 - val_loss: 0.0743\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00002\n",
      "Epoch 30/30\n",
      "329/329 [==============================] - 236s 716ms/step - loss: 0.1498 - val_loss: 3.7913\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00002\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 30\n",
    "\n",
    "model = VGG_DataAug(width=66, height=200, depth=3)\n",
    "print (model.summary())\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4), loss=\"mse\")\n",
    "\n",
    "filepath = \"/home/jupyter/Project/VGG/VGG_DA_Chekpoints/VGG_DA_weights.{epoch:02d}-{val_loss:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "                train_generator,\n",
    "                steps_per_epoch=329,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=37,\n",
    "                callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss: 0.19190431875454264\n",
      "avg_val_loss: 0.7804554499551766\n",
      "difference: -0.588551131200634\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, NUM_EPOCHS), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, NUM_EPOCHS), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# https://stackoverflow.com/questions/4700614/how-to-put-the-legend-out-of-the-plot\n",
    "ax = plt.subplot(111)\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "avg_train_loss = sum(history.history[\"loss\"])/NUM_EPOCHS\n",
    "avg_val_loss = sum(history.history[\"val_loss\"])/NUM_EPOCHS\n",
    "\n",
    "print(\"avg_train_loss: \" + str(avg_train_loss))\n",
    "print(\"avg_val_loss: \" + str(avg_val_loss))\n",
    "print(\"difference: \" + str(avg_train_loss - avg_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8951 validated image filenames.\n",
      "Predictions:  (8951, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=testDF,\n",
    "directory=\"/home/jupyter/Project/test/\",\n",
    "x_col=\"Images\",\n",
    "# y_col=\"SteeringAngle\",\n",
    "y_col=None,    \n",
    "batch_size=100,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(200, 66))\n",
    "\n",
    "filepath = \"/home/jupyter/Project/VGG/VGG_DA_Chekpoints/VGG_DA_weights.01-0.00.h5\"\n",
    "\n",
    "model.load_weights(filepath)\n",
    "\n",
    "\n",
    "predictions = model.predict(test_generator)\n",
    "print('Predictions: ', predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae_sum: 1967.5350901132474\n",
      "len(df_preds): 8951\n",
      "MAE: 0.21981176294416796\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Images = testDF['Images']\n",
    "preds = predictions\n",
    "actual = testDF['SteeringAngle']\n",
    "\n",
    "df_preds = pd.DataFrame(Images)\n",
    "df_preds['Actual Steering Angle'] = (actual * (pi / 180))\n",
    "df_preds['Predicted Steering Angle'] = preds\n",
    "df_preds.rename(columns = {0:'Images'}, inplace = True) \n",
    "\n",
    "df_preds['MAE'] = 0\n",
    "\n",
    "for i in range(len(df_preds)):\n",
    "  df_preds.iloc[i, -1] = abs(df_preds.iloc[i, 1] - df_preds.iloc[i, 2])\n",
    "\n",
    "mae_sum = 0\n",
    "for i in range(len(df_preds)):\n",
    "    mae_sum += df_preds.iloc[i, -1]\n",
    "    \n",
    "print(\"mae_sum: \" + str(mae_sum))    \n",
    "MAE = mae_sum / len(df_preds)\n",
    "print(\"len(df_preds): \" + str(len(df_preds)))\n",
    "print(\"MAE: \" + str(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Images</th>\n",
       "      <th>Actual Steering Angle</th>\n",
       "      <th>Predicted Steering Angle</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8900</th>\n",
       "      <td>45355.jpg</td>\n",
       "      <td>0.103847</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.101977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8901</th>\n",
       "      <td>45356.jpg</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>0.096824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8902</th>\n",
       "      <td>45357.jpg</td>\n",
       "      <td>0.093201</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.087756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8903</th>\n",
       "      <td>45358.jpg</td>\n",
       "      <td>0.089710</td>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.081174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>45359.jpg</td>\n",
       "      <td>0.086219</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.078621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8905</th>\n",
       "      <td>45360.jpg</td>\n",
       "      <td>0.080983</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>0.075807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8906</th>\n",
       "      <td>45361.jpg</td>\n",
       "      <td>0.074002</td>\n",
       "      <td>0.006343</td>\n",
       "      <td>0.067659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8907</th>\n",
       "      <td>45362.jpg</td>\n",
       "      <td>0.074002</td>\n",
       "      <td>0.008182</td>\n",
       "      <td>0.065820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8908</th>\n",
       "      <td>45363.jpg</td>\n",
       "      <td>0.066846</td>\n",
       "      <td>0.010162</td>\n",
       "      <td>0.056684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8909</th>\n",
       "      <td>45364.jpg</td>\n",
       "      <td>0.063355</td>\n",
       "      <td>0.008220</td>\n",
       "      <td>0.055135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8910</th>\n",
       "      <td>45365.jpg</td>\n",
       "      <td>0.054629</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.048768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>45366.jpg</td>\n",
       "      <td>0.045728</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.040668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8912</th>\n",
       "      <td>45367.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.034520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8913</th>\n",
       "      <td>45368.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.022385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8914</th>\n",
       "      <td>45369.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.022276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8915</th>\n",
       "      <td>45370.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>0.020237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8916</th>\n",
       "      <td>45371.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.008626</td>\n",
       "      <td>0.019474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8917</th>\n",
       "      <td>45372.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>0.017735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8918</th>\n",
       "      <td>45373.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.006933</td>\n",
       "      <td>0.021166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8919</th>\n",
       "      <td>45374.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>0.018218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8920</th>\n",
       "      <td>45375.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>0.023082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8921</th>\n",
       "      <td>45376.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.024374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8922</th>\n",
       "      <td>45377.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.019682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>45378.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0.019966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8924</th>\n",
       "      <td>45379.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.022665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>45380.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.023790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8926</th>\n",
       "      <td>45381.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.025459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8927</th>\n",
       "      <td>45382.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.022417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8928</th>\n",
       "      <td>45383.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.023853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8929</th>\n",
       "      <td>45384.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.022009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8930</th>\n",
       "      <td>45385.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.021424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8931</th>\n",
       "      <td>45386.jpg</td>\n",
       "      <td>0.022864</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>0.018473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8932</th>\n",
       "      <td>45387.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.014416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8933</th>\n",
       "      <td>45388.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.014483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8934</th>\n",
       "      <td>45389.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.015640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8935</th>\n",
       "      <td>45390.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.006529</td>\n",
       "      <td>0.014589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8936</th>\n",
       "      <td>45391.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.016584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8937</th>\n",
       "      <td>45392.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>0.015567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8938</th>\n",
       "      <td>45393.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.016375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8939</th>\n",
       "      <td>45394.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.020161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8940</th>\n",
       "      <td>45395.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.016815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8941</th>\n",
       "      <td>45396.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>0.014829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8942</th>\n",
       "      <td>45397.jpg</td>\n",
       "      <td>0.031765</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.027761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8943</th>\n",
       "      <td>45398.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.037843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8944</th>\n",
       "      <td>45399.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.037747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8945</th>\n",
       "      <td>45400.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.035529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8946</th>\n",
       "      <td>45401.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.033843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8947</th>\n",
       "      <td>45402.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.009049</td>\n",
       "      <td>0.029697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8948</th>\n",
       "      <td>45403.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.036753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8949</th>\n",
       "      <td>45404.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.034081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>45405.jpg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.002060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Images  Actual Steering Angle  Predicted Steering Angle       MAE\n",
       "8900  45355.jpg               0.103847                  0.001870  0.101977\n",
       "8901  45356.jpg               0.100356                  0.003533  0.096824\n",
       "8902  45357.jpg               0.093201                  0.005445  0.087756\n",
       "8903  45358.jpg               0.089710                  0.008536  0.081174\n",
       "8904  45359.jpg               0.086219                  0.007598  0.078621\n",
       "8905  45360.jpg               0.080983                  0.005176  0.075807\n",
       "8906  45361.jpg               0.074002                  0.006343  0.067659\n",
       "8907  45362.jpg               0.074002                  0.008182  0.065820\n",
       "8908  45363.jpg               0.066846                  0.010162  0.056684\n",
       "8909  45364.jpg               0.063355                  0.008220  0.055135\n",
       "8910  45365.jpg               0.054629                  0.005861  0.048768\n",
       "8911  45366.jpg               0.045728                  0.005060  0.040668\n",
       "8912  45367.jpg               0.038746                  0.004226  0.034520\n",
       "8913  45368.jpg               0.028100                  0.005714  0.022385\n",
       "8914  45369.jpg               0.028100                  0.005824  0.022276\n",
       "8915  45370.jpg               0.028100                  0.007863  0.020237\n",
       "8916  45371.jpg               0.028100                  0.008626  0.019474\n",
       "8917  45372.jpg               0.028100                  0.010365  0.017735\n",
       "8918  45373.jpg               0.028100                  0.006933  0.021166\n",
       "8919  45374.jpg               0.028100                  0.009881  0.018218\n",
       "8920  45375.jpg               0.026354                  0.003273  0.023082\n",
       "8921  45376.jpg               0.026354                  0.001981  0.024374\n",
       "8922  45377.jpg               0.026354                  0.006673  0.019682\n",
       "8923  45378.jpg               0.026354                  0.006389  0.019966\n",
       "8924  45379.jpg               0.026354                  0.003690  0.022665\n",
       "8925  45380.jpg               0.026354                  0.002564  0.023790\n",
       "8926  45381.jpg               0.028100                  0.002641  0.025459\n",
       "8927  45382.jpg               0.028100                  0.005682  0.022417\n",
       "8928  45383.jpg               0.028100                  0.004246  0.023853\n",
       "8929  45384.jpg               0.026354                  0.004346  0.022009\n",
       "8930  45385.jpg               0.026354                  0.004930  0.021424\n",
       "8931  45386.jpg               0.022864                  0.004390  0.018473\n",
       "8932  45387.jpg               0.021118                  0.006702  0.014416\n",
       "8933  45388.jpg               0.021118                  0.006635  0.014483\n",
       "8934  45389.jpg               0.021118                  0.005478  0.015640\n",
       "8935  45390.jpg               0.021118                  0.006529  0.014589\n",
       "8936  45391.jpg               0.021118                  0.004535  0.016584\n",
       "8937  45392.jpg               0.021118                  0.005552  0.015567\n",
       "8938  45393.jpg               0.021118                  0.004743  0.016375\n",
       "8939  45394.jpg               0.021118                  0.000957  0.020161\n",
       "8940  45395.jpg               0.021118                  0.004303  0.016815\n",
       "8941  45396.jpg               0.021118                  0.006290  0.014829\n",
       "8942  45397.jpg               0.031765                  0.004004  0.027761\n",
       "8943  45398.jpg               0.038746                  0.000903  0.037843\n",
       "8944  45399.jpg               0.038746                  0.000999  0.037747\n",
       "8945  45400.jpg               0.038746                  0.003218  0.035529\n",
       "8946  45401.jpg               0.038746                  0.004903  0.033843\n",
       "8947  45402.jpg               0.038746                  0.009049  0.029697\n",
       "8948  45403.jpg               0.038746                  0.001994  0.036753\n",
       "8949  45404.jpg               0.038746                  0.004665  0.034081\n",
       "8950  45405.jpg               0.000000                  0.002060  0.002060"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds[8900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
