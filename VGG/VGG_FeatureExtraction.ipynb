{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as plb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Conv2D, Lambda, MaxPooling2D, Dropout\n",
    "from keras.utils import print_summary\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG16\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from scipy import pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27342 validated image filenames.\n",
      "Found 9113 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "trainDF = pd.read_csv('/home/jupyter/Project/train.txt', sep=\" \", header=None)\n",
    "trainDF.columns = ['Images', 'SteeringAngle'] \n",
    "trainDF['SteeringAngle'] = trainDF['SteeringAngle'] * (pi / 180)\n",
    "\n",
    "testDF = pd.read_csv('/home/jupyter/Project/test.txt', sep=\" \", header=None)\n",
    "testDF.columns = ['Images', 'SteeringAngle'] \n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.25)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=trainDF,\n",
    "directory=\"/home/jupyter/Project/train/\",\n",
    "x_col=\"Images\",\n",
    "y_col=\"SteeringAngle\",\n",
    "subset=\"training\",\n",
    "batch_size=100,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=\"raw\",\n",
    "target_size=(200,66))\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "dataframe=trainDF,\n",
    "directory=\"/home/jupyter/Project/train/\",\n",
    "x_col=\"Images\",\n",
    "y_col=\"SteeringAngle\",\n",
    "subset=\"validation\",\n",
    "batch_size=100,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=\"raw\",\n",
    "target_size=(200,66))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def VGG_FE(width, height, depth):\n",
    "\n",
    "    conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(height, width, depth))\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(conv_base)\n",
    "    conv_base.trainable = False\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(Dense(1164, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='relu'))    \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 6, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1164)              7152780   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1164)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 21,989,539\n",
      "Trainable params: 7,274,851\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "329/329 [==============================] - 133s 403ms/step - loss: 0.2121 - val_loss: 0.0016\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00159, saving model to /home/jupyter/Project/VGG/VGG_FE_Chekpoints/VGG_FE_weights.01-0.00.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.5/site-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "329/329 [==============================] - 124s 376ms/step - loss: 0.1550 - val_loss: 0.0024\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00159\n",
      "Epoch 3/30\n",
      "329/329 [==============================] - 125s 380ms/step - loss: 0.1490 - val_loss: 0.0811\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00159\n",
      "Epoch 4/30\n",
      "329/329 [==============================] - 124s 377ms/step - loss: 0.1094 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00159\n",
      "Epoch 5/30\n",
      "329/329 [==============================] - 123s 375ms/step - loss: 0.0934 - val_loss: 0.0364\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00159\n",
      "Epoch 6/30\n",
      "329/329 [==============================] - 124s 378ms/step - loss: 0.0798 - val_loss: 0.0885\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00159\n",
      "Epoch 7/30\n",
      "329/329 [==============================] - 124s 377ms/step - loss: 0.0679 - val_loss: 0.0161\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00159\n",
      "Epoch 8/30\n",
      "329/329 [==============================] - 125s 379ms/step - loss: 0.0531 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00159\n",
      "Epoch 9/30\n",
      "329/329 [==============================] - 123s 375ms/step - loss: 0.0516 - val_loss: 0.0472\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00159\n",
      "Epoch 10/30\n",
      "329/329 [==============================] - 124s 376ms/step - loss: 0.0490 - val_loss: 0.0267\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00159\n",
      "Epoch 11/30\n",
      "329/329 [==============================] - 125s 379ms/step - loss: 0.0390 - val_loss: 0.1729\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00159\n",
      "Epoch 12/30\n",
      "329/329 [==============================] - 124s 377ms/step - loss: 0.0344 - val_loss: 0.0031\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00159\n",
      "Epoch 13/30\n",
      "329/329 [==============================] - 125s 380ms/step - loss: 0.0366 - val_loss: 0.0352\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00159\n",
      "Epoch 14/30\n",
      "329/329 [==============================] - 124s 378ms/step - loss: 0.0345 - val_loss: 0.0993\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00159\n",
      "Epoch 15/30\n",
      "329/329 [==============================] - 123s 375ms/step - loss: 0.0328 - val_loss: 16.6085\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00159\n",
      "Epoch 16/30\n",
      "329/329 [==============================] - 124s 377ms/step - loss: 0.0334 - val_loss: 0.0203\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00159\n",
      "Epoch 17/30\n",
      "329/329 [==============================] - 124s 375ms/step - loss: 0.0330 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00159\n",
      "Epoch 18/30\n",
      "329/329 [==============================] - 125s 379ms/step - loss: 0.0316 - val_loss: 0.0023\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00159\n",
      "Epoch 19/30\n",
      "329/329 [==============================] - 124s 376ms/step - loss: 0.0269 - val_loss: 0.0555\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00159\n",
      "Epoch 20/30\n",
      "329/329 [==============================] - 123s 375ms/step - loss: 0.0263 - val_loss: 1.8412\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00159\n",
      "Epoch 21/30\n",
      "329/329 [==============================] - 124s 378ms/step - loss: 0.0270 - val_loss: 0.0448\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00159\n",
      "Epoch 22/30\n",
      "329/329 [==============================] - 124s 376ms/step - loss: 0.0205 - val_loss: 0.0256\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00159\n",
      "Epoch 23/30\n",
      "329/329 [==============================] - 125s 381ms/step - loss: 0.0194 - val_loss: 0.0183\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00159\n",
      "Epoch 24/30\n",
      "329/329 [==============================] - 124s 376ms/step - loss: 0.0259 - val_loss: 0.0314\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00159\n",
      "Epoch 25/30\n",
      "329/329 [==============================] - 124s 376ms/step - loss: 0.0251 - val_loss: 0.6807\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00159\n",
      "Epoch 26/30\n",
      "329/329 [==============================] - 125s 379ms/step - loss: 0.0234 - val_loss: 0.0533\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00159\n",
      "Epoch 27/30\n",
      "329/329 [==============================] - 124s 376ms/step - loss: 0.0199 - val_loss: 0.1577\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00159\n",
      "Epoch 28/30\n",
      "329/329 [==============================] - 125s 380ms/step - loss: 0.0197 - val_loss: 0.0193\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00159\n",
      "Epoch 29/30\n",
      "329/329 [==============================] - 124s 377ms/step - loss: 0.0229 - val_loss: 0.0146\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00159\n",
      "Epoch 30/30\n",
      "329/329 [==============================] - 123s 375ms/step - loss: 0.0202 - val_loss: 1.8194\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00159\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 30\n",
    "\n",
    "model = VGG_FE(width=66, height=200, depth=3)\n",
    "print (model.summary())\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4), loss=\"mse\")\n",
    "\n",
    "filepath = \"/home/jupyter/Project/VGG/VGG_FE_Chekpoints/VGG_FE_weights.{epoch:02d}-{val_loss:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
    "# callbacks_list = [checkpoint1]\n",
    "\n",
    "history = model.fit(\n",
    "                train_generator,\n",
    "                steps_per_epoch=329,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=37,\n",
    "                callbacks=[checkpoint])\n",
    "\n",
    "# model.save_weights(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train_loss: 0.05239775392958009\n",
      "avg_val_loss: 0.7341998379250678\n",
      "difference: -0.6818020839954877\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, NUM_EPOCHS), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, NUM_EPOCHS), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "# https://stackoverflow.com/questions/4700614/how-to-put-the-legend-out-of-the-plot\n",
    "ax = plt.subplot(111)\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "avg_train_loss = sum(history.history[\"loss\"])/NUM_EPOCHS\n",
    "avg_val_loss = sum(history.history[\"val_loss\"])/NUM_EPOCHS\n",
    "\n",
    "print(\"avg_train_loss: \" + str(avg_train_loss))\n",
    "print(\"avg_val_loss: \" + str(avg_val_loss))\n",
    "print(\"difference: \" + str(avg_train_loss - avg_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8951 validated image filenames.\n",
      "Predictions:  (8951, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=testDF,\n",
    "directory=\"/home/jupyter/Project/test/\",\n",
    "x_col=\"Images\",\n",
    "# y_col=\"SteeringAngle\",\n",
    "y_col=None,    \n",
    "batch_size=100,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(200, 66))\n",
    "\n",
    "filepath = \"/home/jupyter/Project/VGG/VGG_FE_Chekpoints/VGG_FE_weights.01-0.00.h5\"\n",
    "\n",
    "model.load_weights(filepath)\n",
    "\n",
    "\n",
    "predictions = model.predict(test_generator)\n",
    "print('Predictions: ', predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae_sum: 1928.2597652030115\n",
      "len(df_preds): 8951\n",
      "MAE: 0.21542394874349363\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Images = testDF['Images']\n",
    "preds = predictions\n",
    "actual = testDF['SteeringAngle']\n",
    "\n",
    "df_preds = pd.DataFrame(Images)\n",
    "df_preds['Actual Steering Angle'] = (actual * (pi / 180))\n",
    "df_preds['Predicted Steering Angle'] = preds\n",
    "df_preds.rename(columns = {0:'Images'}, inplace = True) \n",
    "\n",
    "df_preds['MAE'] = 0\n",
    "\n",
    "for i in range(len(df_preds)):\n",
    "  df_preds.iloc[i, -1] = abs(df_preds.iloc[i, 1] - df_preds.iloc[i, 2])\n",
    "\n",
    "mae_sum = 0\n",
    "for i in range(len(df_preds)):\n",
    "    mae_sum += df_preds.iloc[i, -1]\n",
    "    \n",
    "print(\"mae_sum: \" + str(mae_sum))    \n",
    "MAE = mae_sum / len(df_preds)\n",
    "print(\"len(df_preds): \" + str(len(df_preds)))\n",
    "print(\"MAE: \" + str(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Images</th>\n",
       "      <th>Actual Steering Angle</th>\n",
       "      <th>Predicted Steering Angle</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8900</th>\n",
       "      <td>45355.jpg</td>\n",
       "      <td>0.103847</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>0.091153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8901</th>\n",
       "      <td>45356.jpg</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>0.087401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8902</th>\n",
       "      <td>45357.jpg</td>\n",
       "      <td>0.093201</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.084983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8903</th>\n",
       "      <td>45358.jpg</td>\n",
       "      <td>0.089710</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.082240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8904</th>\n",
       "      <td>45359.jpg</td>\n",
       "      <td>0.086219</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.080377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8905</th>\n",
       "      <td>45360.jpg</td>\n",
       "      <td>0.080983</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.076875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8906</th>\n",
       "      <td>45361.jpg</td>\n",
       "      <td>0.074002</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.072203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8907</th>\n",
       "      <td>45362.jpg</td>\n",
       "      <td>0.074002</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.071856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8908</th>\n",
       "      <td>45363.jpg</td>\n",
       "      <td>0.066846</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.065767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8909</th>\n",
       "      <td>45364.jpg</td>\n",
       "      <td>0.063355</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>0.060332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8910</th>\n",
       "      <td>45365.jpg</td>\n",
       "      <td>0.054629</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.054141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>45366.jpg</td>\n",
       "      <td>0.045728</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.045289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8912</th>\n",
       "      <td>45367.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.038520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8913</th>\n",
       "      <td>45368.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.026152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8914</th>\n",
       "      <td>45369.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.026844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8915</th>\n",
       "      <td>45370.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.024411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8916</th>\n",
       "      <td>45371.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>0.023761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8917</th>\n",
       "      <td>45372.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>0.021197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8918</th>\n",
       "      <td>45373.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.019351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8919</th>\n",
       "      <td>45374.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.007793</td>\n",
       "      <td>0.020307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8920</th>\n",
       "      <td>45375.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.023988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8921</th>\n",
       "      <td>45376.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.023621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8922</th>\n",
       "      <td>45377.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.022688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>45378.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.003044</td>\n",
       "      <td>0.023311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8924</th>\n",
       "      <td>45379.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.024462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8925</th>\n",
       "      <td>45380.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.024622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8926</th>\n",
       "      <td>45381.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.024839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8927</th>\n",
       "      <td>45382.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.026102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8928</th>\n",
       "      <td>45383.jpg</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.025171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8929</th>\n",
       "      <td>45384.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.022839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8930</th>\n",
       "      <td>45385.jpg</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.023477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8931</th>\n",
       "      <td>45386.jpg</td>\n",
       "      <td>0.022864</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.020139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8932</th>\n",
       "      <td>45387.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.018698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8933</th>\n",
       "      <td>45388.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.018356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8934</th>\n",
       "      <td>45389.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.018069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8935</th>\n",
       "      <td>45390.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.019915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8936</th>\n",
       "      <td>45391.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.017716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8937</th>\n",
       "      <td>45392.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>0.014851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8938</th>\n",
       "      <td>45393.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.003108</td>\n",
       "      <td>0.018011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8939</th>\n",
       "      <td>45394.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.016691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8940</th>\n",
       "      <td>45395.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.015465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8941</th>\n",
       "      <td>45396.jpg</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>0.005964</td>\n",
       "      <td>0.015154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8942</th>\n",
       "      <td>45397.jpg</td>\n",
       "      <td>0.031765</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>0.025617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8943</th>\n",
       "      <td>45398.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.028964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8944</th>\n",
       "      <td>45399.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.009462</td>\n",
       "      <td>0.029285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8945</th>\n",
       "      <td>45400.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.034888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8946</th>\n",
       "      <td>45401.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.032545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8947</th>\n",
       "      <td>45402.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.033696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8948</th>\n",
       "      <td>45403.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.011651</td>\n",
       "      <td>0.027095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8949</th>\n",
       "      <td>45404.jpg</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.028737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>45405.jpg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.008301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Images  Actual Steering Angle  Predicted Steering Angle       MAE\n",
       "8900  45355.jpg               0.103847                  0.012694  0.091153\n",
       "8901  45356.jpg               0.100356                  0.012955  0.087401\n",
       "8902  45357.jpg               0.093201                  0.008217  0.084983\n",
       "8903  45358.jpg               0.089710                  0.007470  0.082240\n",
       "8904  45359.jpg               0.086219                  0.005842  0.080377\n",
       "8905  45360.jpg               0.080983                  0.004108  0.076875\n",
       "8906  45361.jpg               0.074002                  0.001799  0.072203\n",
       "8907  45362.jpg               0.074002                  0.002146  0.071856\n",
       "8908  45363.jpg               0.066846                  0.001079  0.065767\n",
       "8909  45364.jpg               0.063355                  0.003023  0.060332\n",
       "8910  45365.jpg               0.054629                  0.000488  0.054141\n",
       "8911  45366.jpg               0.045728                  0.000439  0.045289\n",
       "8912  45367.jpg               0.038746                  0.000226  0.038520\n",
       "8913  45368.jpg               0.028100                  0.001947  0.026152\n",
       "8914  45369.jpg               0.028100                  0.001256  0.026844\n",
       "8915  45370.jpg               0.028100                  0.003689  0.024411\n",
       "8916  45371.jpg               0.028100                  0.004338  0.023761\n",
       "8917  45372.jpg               0.028100                  0.006903  0.021197\n",
       "8918  45373.jpg               0.028100                  0.008748  0.019351\n",
       "8919  45374.jpg               0.028100                  0.007793  0.020307\n",
       "8920  45375.jpg               0.026354                  0.002367  0.023988\n",
       "8921  45376.jpg               0.026354                  0.002734  0.023621\n",
       "8922  45377.jpg               0.026354                  0.003666  0.022688\n",
       "8923  45378.jpg               0.026354                  0.003044  0.023311\n",
       "8924  45379.jpg               0.026354                  0.001893  0.024462\n",
       "8925  45380.jpg               0.026354                  0.001733  0.024622\n",
       "8926  45381.jpg               0.028100                  0.003260  0.024839\n",
       "8927  45382.jpg               0.028100                  0.001998  0.026102\n",
       "8928  45383.jpg               0.028100                  0.002928  0.025171\n",
       "8929  45384.jpg               0.026354                  0.003515  0.022839\n",
       "8930  45385.jpg               0.026354                  0.002878  0.023477\n",
       "8931  45386.jpg               0.022864                  0.002724  0.020139\n",
       "8932  45387.jpg               0.021118                  0.002420  0.018698\n",
       "8933  45388.jpg               0.021118                  0.002763  0.018356\n",
       "8934  45389.jpg               0.021118                  0.003049  0.018069\n",
       "8935  45390.jpg               0.021118                  0.001203  0.019915\n",
       "8936  45391.jpg               0.021118                  0.003403  0.017716\n",
       "8937  45392.jpg               0.021118                  0.006267  0.014851\n",
       "8938  45393.jpg               0.021118                  0.003108  0.018011\n",
       "8939  45394.jpg               0.021118                  0.004428  0.016691\n",
       "8940  45395.jpg               0.021118                  0.005654  0.015465\n",
       "8941  45396.jpg               0.021118                  0.005964  0.015154\n",
       "8942  45397.jpg               0.031765                  0.006148  0.025617\n",
       "8943  45398.jpg               0.038746                  0.009782  0.028964\n",
       "8944  45399.jpg               0.038746                  0.009462  0.029285\n",
       "8945  45400.jpg               0.038746                  0.003859  0.034888\n",
       "8946  45401.jpg               0.038746                  0.006202  0.032545\n",
       "8947  45402.jpg               0.038746                  0.005051  0.033696\n",
       "8948  45403.jpg               0.038746                  0.011651  0.027095\n",
       "8949  45404.jpg               0.038746                  0.010009  0.028737\n",
       "8950  45405.jpg               0.000000                  0.008301  0.008301"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds[8900:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
